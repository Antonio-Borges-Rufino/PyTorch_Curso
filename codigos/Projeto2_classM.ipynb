{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto2_classM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. Projeto 2, Classificação multindex com pytorch\n"
      ],
      "metadata": {
        "id": "-55TeC4tyH_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Importando as bibliotecas"
      ],
      "metadata": {
        "id": "4q6XWJxryP12"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fP9D8zYRwyXY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "import torch \n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Importando os dados"
      ],
      "metadata": {
        "id": "J6MEWtns1CCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/iris.csv')\n",
        "class_predict = df.pop('class')"
      ],
      "metadata": {
        "id": "G8n0vB6C1Fkj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Transformando os dados em np array"
      ],
      "metadata": {
        "id": "89ksxPIN2lpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entradas = np.array(df,dtype='float')\n",
        "saidas_desejadas = class_predict.values"
      ],
      "metadata": {
        "id": "dRFXGYte27NW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Criando saida para multiclasses com probabilidade\n",
        "1. Aqui vou fazer algo diferente, em vez de criar um modelo para prever uma classe, vou criar um pra prever a probabilidade entre as 3 classes, fazendo uma saidade de 3 classes, em vez de apenas 1"
      ],
      "metadata": {
        "id": "7G3yel0bBzA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.1 Criando um dicionario para cada saida"
      ],
      "metadata": {
        "id": "yghXuD6RCFVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saidas_unicas = np.unique(saidas_desejadas)\n",
        "saidas = dict()\n",
        "count = 1\n",
        "for sd in saidas_unicas:\n",
        "  saidas[sd] = count\n",
        "  count = count+1"
      ],
      "metadata": {
        "id": "Y-YXJe6JCJcB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.2 Criando a saida "
      ],
      "metadata": {
        "id": "srE2awYUYOTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saida_df = list()\n",
        "for saida in saidas_desejadas:\n",
        "  lis = list()\n",
        "  for instancia in saidas:\n",
        "    if saida == instancia:\n",
        "      lis.append(1)\n",
        "    else:\n",
        "      lis.append(-1)\n",
        "  saida_df.append(lis)\n",
        "saida_df = np.array(saida_df)"
      ],
      "metadata": {
        "id": "Ba-GLYRk3RzF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Normalizando as entradas"
      ],
      "metadata": {
        "id": "IBSudPWydO8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entradas_norm = MaxAbsScaler().fit(entradas)\n",
        "entradas_norm = entradas_norm.transform(entradas)"
      ],
      "metadata": {
        "id": "zoBntAtidR2p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Definindo o fator randomico de reprodutibilidade para 1"
      ],
      "metadata": {
        "id": "r6npc1BYnEdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EVO_DlHnLar",
        "outputId": "fa625e5d-f880-48e3-c28e-d68a3fe12eb7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7facedf67cf0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Criando a rede neural\n"
      ],
      "metadata": {
        "id": "ClCjOXqlnWQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class classificador(nn.Module):\n",
        "  def __init__(self):#inicia o construtor\n",
        "    super().__init__()\n",
        "    self.camada0 = nn.Linear(in_features = 4, out_features = 5)\n",
        "    torch.nn.init.uniform_(self.camada0.weight)\n",
        "    self.ativacao0 = nn.ReLU()\n",
        "    self.dp0 = nn.Dropout(0.2)\n",
        "    self.camada1 = nn.Linear(in_features = 5, out_features = 5)\n",
        "    torch.nn.init.uniform_(self.camada1.weight)\n",
        "    self.ativacao1 = nn.ReLU()\n",
        "    self.dp1 = nn.Dropout(0.2)\n",
        "    self.camada2 = nn.Linear(in_features=5, out_features=3)\n",
        "    torch.nn.init.uniform_(self.camada2.weight)\n",
        "    self.output = nn.Softmax(dim=-1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.camada0(x)\n",
        "    x = self.ativacao0(x)\n",
        "    x = self.dp0(x)\n",
        "    x = self.camada1(x)\n",
        "    x = self.ativacao1(x)\n",
        "    x = self.dp1(x)\n",
        "    x = self.camada2(x)\n",
        "    x = self.output(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "qJk4yaU3nboy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9. Criando uma função de validação cruzada própria"
      ],
      "metadata": {
        "id": "8uNQ9zZZsLqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class cross_Validation():\n",
        "  def __init__(self,classificador,entrada,saida,cv):#inicia o construtor\n",
        "    self.model = classificador\n",
        "    self.x = entrada\n",
        "    self.y = saida\n",
        "    self.cv = cv\n",
        "  \n",
        "  def rede(self,classificador):\n",
        "    return classificador()\n",
        "\n",
        "  def split_data(self):\n",
        "    self.x = np.array_split(self.x,self.cv)\n",
        "    self.y = np.array_split(self.y,self.cv)\n",
        "  \n",
        "  def transform(self):\n",
        "    self.split_data()\n",
        "    self.x = torch.tensor(self.x,dtype=torch.float)\n",
        "    self.y = torch.tensor(self.y,dtype=torch.long)\n",
        "  \n",
        "  def treinar(self,x,y):\n",
        "    model = self.rede(self.model)\n",
        "    er = nn.MultiLabelMarginLoss()\n",
        "    otm = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.0001)\n",
        "    error = 0.0\n",
        "    for epoch in range(100):\n",
        "      ls = 0.0\n",
        "      for npt,otp in zip(x,y):\n",
        "        otm.zero_grad() \n",
        "        outputs = model.forward(npt) \n",
        "        loss = er(outputs,otp) #Calcula o erro\n",
        "        loss.backward() #reajusta os pesos\n",
        "        otm.step() #calcula o gradiente\n",
        "        ls = ls+loss.item()# Calcula o erro global\n",
        "      error = error + ls\n",
        "    #error = error/len(x)\n",
        "    return model\n",
        "\n",
        "  def avaliar(self,x_treino,y_treino,x_teste,y_teste):\n",
        "    lista = list()\n",
        "    model = self.treinar(x_treino,y_treino)\n",
        "    model.eval()\n",
        "    prev = model.forward(x_teste)\n",
        "    prev = prev.detach().numpy()\n",
        "    for x in prev:\n",
        "      for z in x:\n",
        "        maior = np.argmax(z)\n",
        "        for y in range(len(z)):\n",
        "          if z[y] == z[maior]:\n",
        "            z[y] = 1\n",
        "          else:\n",
        "            z[y] = -1\n",
        "        lista.append(z)    \n",
        "    '''\n",
        "    for x in prev:\n",
        "      req_index=np.argmax(x)\n",
        "      for z in range(len(x)):\n",
        "        if x[z] == x[req_index]:\n",
        "          x[z] = 1\n",
        "        else:\n",
        "          x[z] = -1\n",
        "      lista.append(x)\n",
        "    '''\n",
        "    lista = np.array(lista)\n",
        "    return lista\n",
        "\n",
        "  def conjunto(self,x,y,k):\n",
        "    saida_treino = list()\n",
        "    entrada_treino = list()\n",
        "    saida_test = list()\n",
        "    entrada_test = list()\n",
        "    for indice in range(len(y)):\n",
        "      if indice == k:\n",
        "        saida_test.append(y[indice])\n",
        "      else:\n",
        "        saida_treino.append(y[indice]) \n",
        "    for indice in range(len(x)):\n",
        "      if indice == k:\n",
        "        entrada_test.append(x[indice])\n",
        "      else:\n",
        "        entrada_treino.append(x[indice])\n",
        "    \n",
        "    entrada_treino = torch.tensor(entrada_treino,dtype=torch.float)\n",
        "    entrada_test = torch.tensor(entrada_test,dtype=torch.float)\n",
        "    saida_treino = torch.tensor(saida_treino,dtype=torch.long)\n",
        "    saida_test = torch.tensor(saida_test,dtype=torch.long)\n",
        "    return entrada_treino,entrada_test,saida_test,saida_treino \n",
        "\n",
        "  def fit(self):\n",
        "    self.transform()\n",
        "    x_data = self.x.detach().numpy()\n",
        "    y_data = self.y.detach().numpy()\n",
        "    for k in range(self.cv):\n",
        "      x_treino,x_teste,y_teste,y_treino = self.conjunto(x_data,y_data,k) \n",
        "      resposta = self.avaliar(x_treino,y_treino,x_teste,y_teste)\n",
        "      for x,y in zip(resposta,y_teste):\n",
        "        print('{} : {}'.format(x,y))"
      ],
      "metadata": {
        "id": "s7nNOwSDhYJx"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cl = cross_Validation(classificador=classificador,entrada=entradas_norm,saida=saida_df,cv=5)\n",
        "#entradas_norm = torch.tensor(entradas_norm,dtype=torch.float)\n",
        "#saida_df = torch.tensor(saida_df,dtype=torch.long)"
      ],
      "metadata": {
        "id": "ja82hgQ3tZo0"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cl.fit()"
      ],
      "metadata": {
        "id": "9PMWo6bQukhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5649aab-ebb2-4281-ca1a-d1b6a82126a4"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.  1. -1.] : tensor([[ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1]])\n",
            "[-1.  1. -1.] : tensor([[ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [ 1, -1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1]])\n",
            "[-1.  1. -1.] : tensor([[-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1]])\n",
            "[-1.  1. -1.] : tensor([[-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1,  1, -1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1]])\n",
            "[-1.  1. -1.] : tensor([[-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1],\n",
            "        [-1, -1,  1]])\n"
          ]
        }
      ]
    }
  ]
}